<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>ldpred</title>
  <meta name="description" content="Posting ground for my projects and musings within grad school (and hopefully beyond!)">

  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css" integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">
  <link rel="stylesheet" href="/assets/css/main.css">
</head>

  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <body>
      <section id="page_header">
        <div class="shortParticle">
<div id="particles-js">
  <div class="page-header">
      <h1>
        <span class="site-title">Scott Kulm</span>
        <span class="site-description">Graduate Student</span>
      </h1>
  </div>
</div>
</div>

      </section>
    <div class="forMarkdown">
      <h1 id="ldpred-derivation">LDPred Derivation</h1>

<h2 id="introduction">Introduction</h2>

<p>In this section I will attempt to derive the LDPred method for shrinking GWAS effect sizes so they may be used in polygenic risk scoring.  In this process I will mention other papers that use Bayes Law to estimate the posterior GWAS effect size.  The <a href="https://www.cell.com/action/showPdf?pii=S0002-9297%2815%2900365-1">paper</a> has its own derivation, however I found that many steps were missed or even wrong.  Please contact me if you find any errors within this derivation.</p>

<h2 id="no-ld---infintesimal">No LD - Infintesimal</h2>

<h3 id="calculate-estimated-beta">Calculate Estimated Beta</h3>

<p>As within nearly all polygenic risk score methods, LDPred begins with a simple linear model connecting phenotypes and genotypes.  Note that in this equation we are regressing all of the variants simultaneously.  This is not how GWASs are carried out, and therefore summary statistics are generated.  However it is the most accurate yet simple model.</p>

<script type="math/tex; mode=display">Y = X\beta + \epsilon</script>

<p><script type="math/tex">Y</script> is a <script type="math/tex">N \times 1</script> vector of phenotypes, <script type="math/tex">X</script> is a <script type="math/tex">N \times M</script> genotype matrix, <script type="math/tex">\beta</script> is a <script type="math/tex">M \times 1</script> vector of effects, and <script type="math/tex">\epsilon</script> is a <script type="math/tex">N \times 1</script> vector of error terms.  An assumption is made that the <script type="math/tex">Y</script> vector and each column/variant within <script type="math/tex">X</script> has been mean centered and standardized to have variance of 1.</p>

<p>This equation is never explicitly stated (unfortunately), however it can be implied from the application of ordinary least squares (OLS) to obtain the estimated betas - which is the next step.  A typical application of OLS looks like:</p>

<script type="math/tex; mode=display">\tilde{\beta} = (X'X)^{-1}X'Y</script>

<p>We use the over character tilde to signify estimated values.  The LDPred method was written for summary statistics, which are assumed to be generated using univariate regression, or one variant at a time.  Single variant OLS for variant i looks like:</p>

<script type="math/tex; mode=display">\tilde{\beta_i} = (X_i'X_i)^{-1}X_i'Y</script>

<p>While I cannot find a great proof, it is easy to verify through simulation that if <script type="math/tex">X_i</script> has a mean of 0 and sd of 1:</p>

<script type="math/tex; mode=display">X_i'X_i = \sum_{j=1}^N X_{i,j}^2 = N</script>

<p>Therefore our marginal regression turns into:</p>

<script type="math/tex; mode=display">\tilde{\beta_i} = \frac{X_i'Y}{N}</script>

<p>Before moving forward we need to make a few more assumptions, or rather give our variables some prior distributions.  Specifically we let <script type="math/tex">\beta \sim N(0,h^2/M)</script>. The variance is logical, as the greater the heritability of the trait the larger the possibility of getting large impact variants.  Similarly, the greater number of variants the better our estimates can get (similar to the error of the mean).  Since <script type="math/tex">\beta</script> is normally distributed, so is <script type="math/tex">\tilde{\beta}</script>.  We can find the parameters of this normal distribution as follows:</p>

<script type="math/tex; mode=display">\tilde{\beta_i} = (X'X)^{-1}X'Y</script>

<script type="math/tex; mode=display">E[\tilde{\beta_i}] = (X'X)^{-1}X'E[Y]</script>

<script type="math/tex; mode=display">E[\tilde{\beta_i}] = (X'X)^{-1}X'X\beta_i</script>

<script type="math/tex; mode=display">E[\tilde{\beta_i}] = \beta_i</script>

<script type="math/tex; mode=display">Var(y) = Var(X\beta + \epsilon)</script>

<script type="math/tex; mode=display">Var(y) = Var(\epsilon) = 1 - \frac{h^2}{M}</script>

<script type="math/tex; mode=display">Var(\tilde{\beta_i}) = Var((X'X)^{-1}X'Y)</script>

<script type="math/tex; mode=display">Var(\tilde{\beta_i}) = (X'X)^{-1}X'Var(Y)X(X'X)^{-1}</script>

<script type="math/tex; mode=display">Var(\tilde{\beta_i}) = (N)^{-2}X_i'Var(Y)X_i</script>

<script type="math/tex; mode=display">Var(\tilde{\beta_i}) = (N)^{-2}X_i'(1 - \frac{h^2}{M})X_i</script>

<script type="math/tex; mode=display">Var(\tilde{\beta_i}) = (N)^{-2}X_i'X_i(1 - \frac{h^2}{M})</script>

<script type="math/tex; mode=display">Var(\tilde{\beta_i}) = \frac{1-\frac{h^2}{M}}{N}</script>

<p>The more confusing process is the variance, in which we first need to calculate out the variance of y.  For some reason in this case we treat beta as a fixed effect leaving us with the variance of epsilon.  Epsilon is the error term, which accounts for the sum of total variance in the phenotype not accounted by the genotypes.  Therefore it is simply one minus the per SNP heritabiliy (per SNP because this is the variance per variant). Note that I got much of this process from <a href="https://www.cambridge.org/core/books/semiparametric-regression/02FC9A9435232CA67532B4D31874412C">Ruppert</a>, specifically on page 30 in Chapter 2.</p>

<p>Putting both pieces together our final distribution is:</p>

<script type="math/tex; mode=display">\tilde{\beta_i} \sim N(\beta_i,\frac{1-\frac{h^2}{M}}{N})</script>

<h3 id="calculate-posterior-beta">Calculate Posterior Beta</h3>

<p>Now that we have fully defined the estimated beta, we can use this value to work back and get the posterior distribution of beta itself.  While the paper points to <a href="https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1003348">Dudbridge</a>, which points to <a href="https://www.cambridge.org/core/books/semiparametric-regression/02FC9A9435232CA67532B4D31874412C">Ruppert</a>, there is no satisfactory explanation for the seemingly nice result that is achieved.  The work by Dudbrdige would indicate that some BLUP style calculations are needed, but rather this is simply a direct application of Bayes Law:</p>

<script type="math/tex; mode=display">(\beta | \tilde{\beta}) = \frac{(\tilde{\beta} | \beta)(\beta)}{\tilde{\beta}}</script>

<script type="math/tex; mode=display">(\beta | \tilde{\beta}) = \frac{(\tilde{\beta} | \beta)(\beta)}{\int_{-\infty}^{\infty} (\tilde{\beta} | \beta)(\beta) d\beta}</script>

<p>There is no easy way to do this integral but to do it.  I will now substitute in the normal distributions and solve.  Note that the distribution of the estimated beta is simplified to <script type="math/tex">N(\beta,\frac{1}{N})</script>.  I will show this is correct, or at least produces to right result, although it is stated incorrectly within the paper as <script type="math/tex">Var(\beta_i)=1</script>.</p>

<script type="math/tex; mode=display">\int_{-\infty}^{\infty} N(0,\frac{h^2}{M})N(\beta,\frac{1}{N}) d\beta</script>

<script type="math/tex; mode=display">\int_{-\infty}^{\infty}    \frac{1}{\sqrt{2\pi \frac{h^2}{M}}}exp[-\frac{(\beta-0)^2}{2\frac{h^2}{M}}]    \frac{1}{\sqrt{2\pi \frac{1}{N}}}exp[-\frac{(\tilde{\beta}-\beta)^2}{2\frac{1}{N}}]   d\beta</script>

<script type="math/tex; mode=display">\frac{1}{2\pi} \sqrt{\frac{NM}{h^2}}       \int_{-\infty}^{\infty}    exp[-\frac{(\beta-0)^2}{2\frac{h^2}{M}} -\frac{(\tilde{\beta}-\beta)^2}{2\frac{1}{N}}]   d\beta</script>

<script type="math/tex; mode=display">\frac{1}{2\pi} \sqrt{\frac{NM}{h^2}}  \int_{-\infty}^{\infty}  exp[-\frac{1}{2}(\frac{M}{h^2}\beta^2 + N (\tilde{\beta}^2- 2\tilde{\beta}\beta + \beta^2))]   d\beta</script>

<script type="math/tex; mode=display">\frac{1}{2\pi} \sqrt{\frac{NM}{h^2}}  \int_{-\infty}^{\infty}  exp[-\frac{N\tilde{\beta}^2}{2}  + N \beta \tilde{\beta} - \frac{1}{2}(N+\frac{M}{h^2})\beta^2 ]   d\beta</script>

<p>This integral is clearly very difficult to do, so I will refer to a book of integral or in my case Wolfram alpha, which stats:</p>

<script type="math/tex; mode=display">\int_{-\infty}^{\infty} exp[-a + bx -cx^2]dx = \sqrt{\frac{\pi}{c}}exp[\frac{b^2}{4c}-a]</script>

<script type="math/tex; mode=display">a = \frac{N\tilde{\beta}^2}{2}</script>

<script type="math/tex; mode=display">b = N\tilde{\beta}</script>

<script type="math/tex; mode=display">c = \frac{1}{2}(N+\frac{M}{h^2}) = \frac{Nh^2 + M}{2h^2}</script>

<p>Substituting becomes:</p>

<script type="math/tex; mode=display">\sqrt{\frac{\pi}{\frac{Nh^2 + M}{2h^2}}} exp[\frac{N^2\tilde{\beta}^2}{4(\frac{1}{2}(N+\frac{M}{h^2}))} - \frac{N\tilde{\beta}^2}{2}]</script>

<script type="math/tex; mode=display">\sqrt{\frac{2h^2\pi}{Nh^2 + M}} exp[\frac{1}{2} \frac{N^2\tilde{\beta}^2 - (N+\frac{M}{h^2})N\tilde{\beta}^2}{N+\frac{M}{h^2}} ]</script>

<script type="math/tex; mode=display">\sqrt{\frac{2h^2\pi}{Nh^2 + M}} exp[\frac{1}{2} \frac{\frac{Nh^2}{M}\tilde{\beta}^2}{N+\frac{M}{h^2}} ]</script>

<script type="math/tex; mode=display">\sqrt{\frac{2h^2\pi}{Nh^2 + M}} exp[-\frac{1}{2}\frac{\tilde{\beta}^2}{\frac{h^2}{M} + \frac{1}{N}}]</script>

<p>Now bringing back the coefficients we left out previously:</p>

<script type="math/tex; mode=display">\frac{1}{2\pi} \sqrt{\frac{NM}{h^2}} \sqrt{\frac{2h^2\pi}{Nh^2 + M}}exp[-\frac{1}{2}\frac{\tilde{\beta}^2}{\frac{h^2}{M} + \frac{1}{N}}]</script>

<script type="math/tex; mode=display">\frac{1}{\sqrt{2\pi}}\sqrt{\frac{NM}{Nh^2+M}} exp[-\frac{1}{2}\frac{\tilde{\beta}^2}{\frac{h^2}{M} + \frac{1}{N}}]</script>

<script type="math/tex; mode=display">\frac{1}{\sqrt{2\pi}}\sqrt{\frac{1}{\frac{h^2}{M} + \frac{1}{N}}} exp[-\frac{1}{2}\frac{\tilde{\beta}^2}{\frac{h^2}{M} + \frac{1}{N}}]</script>

<p>The integral is done, but we still need to handle the numerator.  Noting that we are assuming the final answer to be a normal distribution all we need are the pieces within the exponent as they can define both the mean and variance.  I have included the constant terms thus far as this integral result in its entirety will come up later:</p>

<script type="math/tex; mode=display">(\beta | \tilde{\beta}) = \frac{N(0,\frac{h^2}{M})N(\beta,\frac{1}{N})}{exp[-\frac{1}{2}\frac{\tilde{\beta}^2}{\frac{h^2}{M} + \frac{1}{N}}]}</script>

<script type="math/tex; mode=display">exp[-\frac{1}{2}\frac{\beta^2}{2\frac{h^2}{M}}] exp[-\frac{1}{2}\frac{(\tilde{\beta}-\beta)^2}{2\frac{1}{N}}] exp[\frac{1}{2}\frac{\tilde{\beta}^2}{\frac{h^2}{M} + \frac{1}{N}}]</script>

    </div>

      </div>
      <footer class="footer">
    <p>&copy; Scott Kulm</p>
    <p>Build with Jekyll and <span class="love">❤</span> by <a href="https://github.com/nrandecker">Nathan Randecker</a></p>
</footer>
<script src="//cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
<script src="/assets/js/sweet-scroll.min.js"></script>
<script src="/assets/js/main.js"></script>
<!-- Google Analytics -->

<script>
var dnt = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
if (dnt != "1" && dnt != "yes") {
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', '', 'auto');
ga('send', 'pageview');
}
</script>



  </body>
